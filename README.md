# TFG Grado Ingenier√≠a Inform√°tica.

El objetivo de este proyecto es realizar un estudio sobre el rendimiento de diferentes bases de datos de series temporales.

**¬°Estos programas deben ser ejecutados en Linux!**

Para ejecutar este proyecto se necesitan los archivos de este repositorio y el directorio con los datos originales que se tendr√°n que solicitar de manera privada si se dispone de los permisos necesarios.

### Instalaci√≥n üîß

Para ejecutar este proyecto debemos instalar las siguientes herramientas de software:

Deberemos comprobar que la versi√≥n que tenemos de Python es la 3 y tener el instalador de paquetes pip. Para ello podr√° ejecutar las siguientes l√≠neas de c√≥digo en su terminal de Linux.
```
sudo apt install python3
sudo apt install pip
```
Tambi√©n tendremos que instalar [Docker](https://docs.docker.com/engine/install/ubuntu/). Para utilizar esta herramienta sin privilegios de superusuario podemos ejecutar lo siguiente:

```
sudo groupadd docker
sudo usermod -aG docker $USER
sudo systemctl restart docker
sudo chmod 666 /var/run/docker.sock
```

### Pre-requisitos üìã

En el archivo *'requirements.txt'* podemos encontrar las bibliotecas de Python que hemos utilizado durante el desarrollo del trabajo. Para instalarlas deberemos ejecutar el siguiente comando y si lo desea puede crear antes un entorno virtual para que no afecten est√°s versiones a otras que tenga instaladas en su m√°quina.

```
pip install -r requirements.txt
```
## Ejecuci√≥n üíª

Teniendo en cuenta que hemos seguido los pasos anteriores y tenemos todo el software necesario, el primer paso ser√° descargar este repositorio y obtener la carpeta *'raw_data'* con los datos originales que ubicaremos en *'TFG_PatriciaAguado/data/'*.

A continuaci√≥n, tendremos que dar permisos de ejecuci√≥n al usuario para los scripts de bash:

```
sudo chmod u+x docker_db.sh
sudo chmod u+x process_data.sh
sudo chmod u+x visualization.sh
```
En primer lugar, abrimos una terminal en 'TFG_PatriciaAguado' y ejecutamos el script 'process_data.sh':
```
./process_data.sh
```
Este se encarga de ejecutar en orden los programas de Python que se encuentran en el directorio *'data'*. Estos consisten en:
* *'read_data.py'*: leer todos los archivos que se encuentran en el directorio *'data/raw_data'* y juntarlos para generar el archivo *'data/silver_data.xlsx'*.
* *'clean_data.py'*: realizar sobre *'silver_data.xlsx'* un proceso de limpieza de datos y generar en el directorio 'data/gold_data'} un archivo con todos los datos de calidad y uno por cada tama√±o especificado (3, 6, 10 y 13 meses).
* *'json_schemas.py'*: crear un directorio *'data/json_schemas'*, en el que se crea un directorio por cada base de datos y en cada uno de ellos un archivo de formato JSON para cada tama√±o.
  
En segundo lugar, una vez que ya tenemos todos los archivos preparados con los datos que queremos insertar para las pruebas de rendimiento en el directorio *'data/json_schemas'* ejecutamos el script *'docker_db.sh'*:
```
./docker_db.sh
```
Este primero monta un contenedor de Docker para nuestra base de datos personal, a partir del script SQL *'docker/scripts_sql/postgresdb.sql'*. Como esta base de datos almacenar√° los resultados, se genera un directorio de persistencia de datos denominado *'docker/postgresdb'*.

Despu√©s, el script contin√∫a montando un contenedor de Docker, realizando pruebas de rendimiento (es decir, ejecutando los programas Python que se encuentran en *'docker/scripts_python'*), guardando los datos recuperados en cada consulta, insertando los resultados de rendimiento en nuestra base de datos y desmontando el contenedor para cada servicio definido en el archivo *'docker/docker-compose.yml'* de forma recursiva.

Al finalizar, se ejecuta el programa *'results_performance.py'* que recupera los resultados de PostgreSQL en un documento XLSX que contiene las tablas con los resultados de las pruebas de rendimiento (*'results_performance.xlsx'*) y que almacena en el directorio *'results'* junto con los resultados de cada consulta en cada experimento.

En √∫ltimo lugar, ejecutamos el script *'visualization.sh'* que nos abrir√° una p√°gina en nuestro navegador por defecto con el puerto 5000, que es en el que se encuentra el servidor de nuestra aplicaci√≥n web de visualizaci√≥n de datos:
```
./visualization.sh
```

## Utilizaci√≥n de la aplicaci√≥n ‚öôÔ∏è
Al abrirse la aplicaci√≥n web nos encontramos con dos opciones:
* **Resultados de consultas**: obtendremos gr√°ficas de puntos o de l√≠neas en funci√≥n de la consulta sobre la que queramos observar los resultados. Podremos filtrar los datos a mostrar seleccionando la base de datos, el tama√±o de meses y el n√∫mero de variables consultadas que queremos. Una vez pulsemos el bot√≥n de actualizar podremos ver el gr√°fico deseado, pero si queremos por ejemplo seleccionar unos identificadores de sensor diferentes podremos elegirlos en las casillas de verificaci√≥n pertinentes y volver a pulsar el bot√≥n de actualizar.
* **Resultados de rendimiento**: obtendremos gr√°ficas de barras agrupadas por tama√±os para los resultados de las pruebas de rendimiento realizadas. Nos encontraremos casillas de verificaci√≥n para seleccionar las bases de datos y los tama√±os del conjunto en meses que queremos comparar. Una vez seleccionado esto y la consulta para la que queremos gr√°ficar los resultados, una vez que pulsemos el bot√≥n actualizar en caso de que sea necesario elegir el n√∫mero de variables consultadas a comparar (porque realizamos consultas preguntando por 1, 5 y 20 variables) aparecer√° una visualizaci√≥n vac√≠a que nos indicar√° que debemos seleccionar este √∫ltimo par√°metro que antes igual no estaba visible. S√≥lo tendremos que pulsar el bot√≥n de actualizar y volver√° a estar disponible.

En ambos nos encontraremos con un bot√≥n para ir atr√°s y con un bot√≥n situado debajo del gr√°fico en la parte derecha para poder descargar la visualizaci√≥n en formato PNG. Adem√°s, los gr√°ficos son interactivos, podemos ampliarlos, modificar las escalas de los ejes o ver informaci√≥n detalla al pasar por encima del dato representado.
Hay que mencionar que, en caso de que no exista la carpeta *'docker/results'* nos aparecer√° una pantalla de error con indicaciones.

En caso de querer ver varios gr√°ficos en diferentes pesta√±as, podemos abrir manualmente la misma direcci√≥n (http://127.0.0.1:5000/) en otra pesta√±a o en otro navegador, siempre y cuando no hayamos detenido el servidor en la terminal. Si queremos cerrar la aplicaci√≥n basta con cerrar el navegador y presionar en la terminal de Linux 'CTRL+C'.

## Construido con üõ†Ô∏è

Las herramientas principales que hemos utilizado para llevar acabo este proyecto son las siguientes:

* [Python](https://www.python.org/) - Lenguaje de programaci√≥n
* [Docker](https://www.docker.com/) - Plataforma basada en la virtualizaci√≥n de entornos aislados para facilitar el despliegue de aplicaciones
* [Sublime Text](https://www.sublimetext.com/) - Usado para generar todos los scripts del trabajo
* [Flask](https://flask.palletsprojects.com/en/3.0.x/) - Usado para la aplicaci√≥n web
* [Plotly](https://plotly.com/python/) - Usado para generar gr√°ficos interactivos 

## Imagenes utilizadas en Docker üñºÔ∏è

Las im√°genes de Docker utilizadas para definir los servicios de bases de datos en el archivo docker-compose.yml son las siguientes:

* [PostgreSQL](https://hub.docker.com/_/postgres) - Imagen oficial de Docker para PostgreSQL
* [InfluxDB](https://hub.docker.com/_/influxdb) - Imagen oficial de Docker para InfluxDB
* [TimescaleDB](https://hub.docker.com/r/timescale/timescaledb) - Imagen de Docker para TimescaleDB
* [OpenTSDB](https://hub.docker.com/r/petergrace/opentsdb-docker) - Imagen de Docker para OpenTSDB
* [KairosDB](https://hub.docker.com/r/elastisys/kairosdb) - Imagen de Docker para KairosDB
* [Cassandra](https://hub.docker.com/_/cassandra) - Imagen oficial de Docker para Cassandra

## Autores ‚úíÔ∏è

* **Patricia Aguado Labrador** - [Patagualab](https://github.com/Patagualab)
